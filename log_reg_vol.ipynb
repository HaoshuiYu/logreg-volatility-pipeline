{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ae4194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0048220",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhian\\AppData\\Local\\Temp\\ipykernel_44624\\179404364.py:5: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  df_raw = yf.download(assets, start = start, end = end, interval = \"1d\")\n",
      "[*********************100%***********************]  3 of 3 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([( 'Close', 'ASML'),\n",
       "            ( 'Close',  'SMH'),\n",
       "            ( 'Close',  'SPY'),\n",
       "            (  'High', 'ASML'),\n",
       "            (  'High',  'SMH'),\n",
       "            (  'High',  'SPY'),\n",
       "            (   'Low', 'ASML'),\n",
       "            (   'Low',  'SMH'),\n",
       "            (   'Low',  'SPY'),\n",
       "            (  'Open', 'ASML'),\n",
       "            (  'Open',  'SMH'),\n",
       "            (  'Open',  'SPY'),\n",
       "            ('Volume', 'ASML'),\n",
       "            ('Volume',  'SMH'),\n",
       "            ('Volume',  'SPY')],\n",
       "           names=['Price', 'Ticker'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data acquisition\n",
    "start = \"2020-01-01\"\n",
    "end = \"2025-12-31\"\n",
    "assets = [\"ASML\", \"SPY\", \"SMH\"]\n",
    "df_raw = yf.download(assets, start = start, end = end, interval = \"1d\")\n",
    "df_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6467b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>ASML</th>\n",
       "      <th>SMH</th>\n",
       "      <th>SPY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-02</th>\n",
       "      <td>286.903198</td>\n",
       "      <td>69.703552</td>\n",
       "      <td>297.698975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-03</th>\n",
       "      <td>282.279877</td>\n",
       "      <td>68.561760</td>\n",
       "      <td>295.444763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-06</th>\n",
       "      <td>280.034485</td>\n",
       "      <td>67.829437</td>\n",
       "      <td>296.571838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-07</th>\n",
       "      <td>283.075806</td>\n",
       "      <td>68.961624</td>\n",
       "      <td>295.737976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-08</th>\n",
       "      <td>286.012634</td>\n",
       "      <td>69.077248</td>\n",
       "      <td>297.314117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-23</th>\n",
       "      <td>1061.839966</td>\n",
       "      <td>363.160004</td>\n",
       "      <td>687.960022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-24</th>\n",
       "      <td>1065.520020</td>\n",
       "      <td>364.170013</td>\n",
       "      <td>690.380005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-26</th>\n",
       "      <td>1072.750000</td>\n",
       "      <td>365.859985</td>\n",
       "      <td>690.309998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-29</th>\n",
       "      <td>1066.000000</td>\n",
       "      <td>364.209991</td>\n",
       "      <td>687.849976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-12-30</th>\n",
       "      <td>1072.140015</td>\n",
       "      <td>363.309998</td>\n",
       "      <td>687.010010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1507 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker             ASML         SMH         SPY\n",
       "Date                                           \n",
       "2020-01-02   286.903198   69.703552  297.698975\n",
       "2020-01-03   282.279877   68.561760  295.444763\n",
       "2020-01-06   280.034485   67.829437  296.571838\n",
       "2020-01-07   283.075806   68.961624  295.737976\n",
       "2020-01-08   286.012634   69.077248  297.314117\n",
       "...                 ...         ...         ...\n",
       "2025-12-23  1061.839966  363.160004  687.960022\n",
       "2025-12-24  1065.520020  364.170013  690.380005\n",
       "2025-12-26  1072.750000  365.859985  690.309998\n",
       "2025-12-29  1066.000000  364.209991  687.849976\n",
       "2025-12-30  1072.140015  363.309998  687.010010\n",
       "\n",
       "[1507 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data organization\n",
    "close_cols = [\n",
    "    (\"Close\", \"ASML\"),\n",
    "    (\"Close\", \"SMH\"),\n",
    "    (\"Close\", \"SPY\"),\n",
    "]\n",
    "df = pd.DataFrame()\n",
    "df_close = df_raw[close_cols].copy()\n",
    "df_close.columns = df_close.columns.droplevel(0)\n",
    "df_close\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5eba5800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2025-12-23   -0.001324\n",
      "2025-12-24   -0.001647\n",
      "2025-12-26   -0.002059\n",
      "2025-12-29   -0.000666\n",
      "2025-12-30   -0.000769\n",
      "Name: ASML_vol_adj_mom, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# input feature 1: ASML vol adjusted momentum\n",
    "L = 10\n",
    "ASML_std = df_close[\"ASML\"].rolling(window=L).std()\n",
    "ASML_avg = df_close[\"ASML\"].rolling(window=L).mean()\n",
    "ASML_returns = df_close[\"ASML\"].pct_change(L)\n",
    "df_close[\"ASML_vol_adj_mom\"] = (ASML_returns/ASML_std).dropna()\n",
    "\n",
    "print(df_close[\"ASML_vol_adj_mom\"].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0f7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input features 2 and 3: SPY and SMH\n",
    "df_close[\"SPY_returns\"] = df_close[\"SPY\"].pct_change(L).dropna()\n",
    "\n",
    "df_close[\"SMH_returns\"] = df_close[\"SMH\"].pct_change(L).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "862bd7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 declare trade threshold y_trade\n",
    "H = 5\n",
    "threshold = 0.03\n",
    "\n",
    "df_close[\"forward_return\"] = (df_close[\"ASML\"].shift(-H)/df_close[\"ASML\"] -1)\n",
    "df_close[\"y_trade\"] = np.where(df_close[\"forward_return\"].notna(),\n",
    "    (df_close[\"forward_return\"] > threshold).astype(int), \n",
    "    np.nan,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47efb085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker      ASML_vol_adj_mom  SPY_returns  SMH_returns  y_trade\n",
      "Date                                                           \n",
      "2020-01-16         -0.002488     0.018623     0.005391      0.0\n",
      "2020-01-17          0.003118     0.029589     0.026351      0.0\n",
      "2020-01-21          0.005217     0.023668     0.038284      0.0\n",
      "2020-01-22         -0.003951     0.026678     0.029621      0.0\n",
      "2020-01-23         -0.009606     0.022407     0.034314      0.0\n",
      "it produces 457 trades\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model_df\n",
    "features = [\n",
    "    \"ASML_vol_adj_mom\",\n",
    "    \"SPY_returns\",\n",
    "    \"SMH_returns\"\n",
    "]\n",
    "\n",
    "target = \"y_trade\"\n",
    "model_cols = features + [target]\n",
    "model_df = df_close[model_cols].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "print(model_df.head())\n",
    "\n",
    "n_trades = (model_df[\"y_trade\"] == 1).sum()\n",
    "print(f\"it produces {n_trades} trades\")\n",
    "\n",
    "len(model_df[\"ASML_vol_adj_mom\"]) == len(model_df[\"y_trade\"])\n",
    "len(model_df[\"y_trade\"]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fe15fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare split\n",
    "X = model_df[features]\n",
    "y = model_df[target]\n",
    "\n",
    "split = int(0.7* len(model_df))\n",
    "\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X.index.equals(y.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b9b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logit\", LogisticRegression(\n",
    "        # regularization  \n",
    "        C = 1e6,\n",
    "        penalty = \"l2\",\n",
    "        # Hessian\n",
    "        solver = \"lbfgs\",\n",
    "        max_iter =  5000,\n",
    "        random_state = 0,\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "981e29a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_c: 0.046415888336127774\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C</th>\n",
       "      <th>cv_log_loss</th>\n",
       "      <th>cv_brier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.046416</td>\n",
       "      <td>0.615540</td>\n",
       "      <td>0.212158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.215443</td>\n",
       "      <td>0.616294</td>\n",
       "      <td>0.212303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.616680</td>\n",
       "      <td>0.212745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.618160</td>\n",
       "      <td>0.213414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.619016</td>\n",
       "      <td>0.213795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          C  cv_log_loss  cv_brier\n",
       "0  0.046416     0.615540  0.212158\n",
       "1  0.215443     0.616294  0.212303\n",
       "2  0.010000     0.616680  0.212745\n",
       "3  0.002154     0.618160  0.213414\n",
       "4  0.000464     0.619016  0.213795"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# C Sweep/Cross-Validation\n",
    "from sklearn.metrics import log_loss, brier_score_loss\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "Cs = np.logspace(-4, 4, 13)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for C in Cs:\n",
    "    clf.set_params(logit__C=float(C))\n",
    "\n",
    "    fold_log_losses = []\n",
    "    fold_briers = []\n",
    "\n",
    "    for tr_idx, va_idx in tscv.split(X_train):\n",
    "        X_tr, X_va = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "        y_tr, y_va = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "\n",
    "        clf.fit(X_tr, y_tr)\n",
    "        p_va = clf.predict_proba(X_va)[:, 1]\n",
    "\n",
    "        fold_log_losses.append(log_loss(y_va, p_va, labels=[0, 1]))\n",
    "        fold_briers.append(brier_score_loss(y_va, p_va))\n",
    "\n",
    "    rows.append((float(C), float(np.mean(fold_log_losses)), float(np.mean(fold_briers))))\n",
    "\n",
    "C_sweep = (\n",
    "    pd.DataFrame(rows, columns=[\"C\", \"cv_log_loss\", \"cv_brier\"])\n",
    "      .sort_values(\"cv_log_loss\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "best_c = float(C_sweep.loc[0, \"C\"])\n",
    "print(\"best_c:\", best_c)\n",
    "\n",
    "C_sweep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf172334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2025-12-16    0.322122\n",
      "2025-12-17    0.354162\n",
      "2025-12-18    0.338988\n",
      "2025-12-19    0.327541\n",
      "2025-12-22    0.318027\n",
      "Name: p test, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# compute best fit/probability\n",
    "clf.set_params(logit__C=best_c)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# output p_train as a diagnostic, not as a used output because it's fitted on X_train\n",
    "p_train = pd.Series(clf.predict_proba(X_train)[:, 1])\n",
    "p_test = pd.Series(clf.predict_proba(X_test)[:, 1], index=y_test.index, name=\"p test\")\n",
    "print(p_test.tail())\n",
    "assert p_test.between(0,1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf91b561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21302843, -0.06247569, -0.27686836]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access coefficients from the nested LogisticRegression estimator in the Pipeline\n",
    "clf.named_steps['logit'].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "feda38f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -0.7893\n",
      "\n",
      "Coefficients (sorted by absolute size):\n",
      "            feature    coef\n",
      "2       SMH_returns -0.2769\n",
      "0  ASML_vol_adj_mom  0.2130\n",
      "1       SPY_returns -0.0625\n"
     ]
    }
   ],
   "source": [
    "# output inspection\n",
    "logit = clf.named_steps[\"logit\"]\n",
    "\n",
    "coefs = logit.coef_[0]\n",
    "intercept = logit.intercept_[0]\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    \"feature\": features,\n",
    "    \"coef\": coefs\n",
    "}).sort_values(\"coef\", key=np.abs, ascending=False)\n",
    "\n",
    "print(\"Intercept:\", round(intercept, 4))\n",
    "print(\"\\nCoefficients (sorted by absolute size):\")\n",
    "print(coef_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83b3974c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training base rate: 0.31417624521072796\n",
      "testing base rate: 0.28794642857142855\n",
      "test average probability: 0.30725167088418376\n"
     ]
    }
   ],
   "source": [
    "# inspection\n",
    "train_base_rate = y_train.mean()\n",
    "test_base_rate = y_test.mean()\n",
    "test_avg_p = p_test.mean()\n",
    "\n",
    "print(f\"training base rate: {train_base_rate}\")\n",
    "print(f\"testing base rate: {test_base_rate}\")\n",
    "print(f\"test average probability: {test_avg_p}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cfecf03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.014532922065462806)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generalization test\n",
    "ll_train = log_loss(y_train, p_train, labels=[0,1])\n",
    "ll_test = log_loss(y_test,  p_test,  labels=[0,1])\n",
    "br_train = brier_score_loss(y_train, p_train)\n",
    "br_test = brier_score_loss(y_test,  p_test)\n",
    "\n",
    "gap_ll = ll_test - ll_train\n",
    "gap_bs = br_test - br_train\n",
    "gap_bs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51b690be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base-rate p0 (train win rate): 0.314\n",
      "log_loss  train  model=0.6147  base=0.6224\n",
      "log_loss  test   model=0.5828  base=0.6019\n",
      "Brier     train  model=0.2121  base=0.2155\n",
      "Brier     test   model=0.1975  base=0.2057\n",
      "Test improvement vs base (log_loss): 3.18%\n",
      "Test improvement vs base (Brier):    3.98%\n"
     ]
    }
   ],
   "source": [
    "# Frequency Calibration\n",
    "p0 = float(train_base_rate)\n",
    "\n",
    "p0_train = np.full(len(y_train), p0)\n",
    "p0_test  = np.full(len(y_test),  p0)\n",
    "\n",
    "ll_train_base = log_loss(y_train, p0_train, labels=[0, 1])\n",
    "ll_test_base  = log_loss(y_test,  p0_test,  labels=[0, 1])\n",
    "\n",
    "br_train_base = brier_score_loss(y_train, p0_train)\n",
    "br_test_base  = brier_score_loss(y_test,  p0_test)\n",
    "\n",
    "improve_ll_test = (ll_test_base - ll_test) / ll_test_base\n",
    "improve_bs_test = (br_test_base - br_test) / br_test_base\n",
    "\n",
    "print(f\"Base-rate p0 (train win rate): {p0:.3f}\")\n",
    "print(f\"log_loss  train  model={ll_train:.4f}  base={ll_train_base:.4f}\")\n",
    "print(f\"log_loss  test   model={ll_test:.4f}  base={ll_test_base:.4f}\")\n",
    "print(f\"Brier     train  model={br_train:.4f}  base={br_train_base:.4f}\")\n",
    "print(f\"Brier     test   model={br_test:.4f}  base={br_test_base:.4f}\")\n",
    "print(f\"Test improvement vs base (log_loss): {improve_ll_test:.2%}\")\n",
    "print(f\"Test improvement vs base (Brier):    {improve_bs_test:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a515e9",
   "metadata": {},
   "source": [
    "Test loss < train loss, unexpected gap. Warrants further inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7967bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Model vs Baseline (SHUFFLED labels) ===\n",
      "log_loss test  model=0.6045  base=0.6019\n",
      "Brier    test  model=0.2068  base=0.2057\n",
      "Test improvement vs base (log_loss):  -0.43%\n",
      "Test improvement vs base (Brier):     -0.55%\n"
     ]
    }
   ],
   "source": [
    "# Leakage test\n",
    "y_train_shuffled = y_train.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "y_train_shuffled\n",
    "\n",
    "shuffled_params = clf.set_params(logit__C=best_c)\n",
    "shuffled_model = clf.fit(X_train, y_train_shuffled)\n",
    "\n",
    "p_train_shuffled = shuffled_model.predict_proba(X_train)[:, 1]\n",
    "p_test_shuffled = shuffled_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "ll_train_shuffled = log_loss(y_train, p_train_shuffled, labels=[0,1])\n",
    "ll_test_shuffled = log_loss(y_test, p_test_shuffled, labels=[0,1])\n",
    "\n",
    "br_train_shuffled = brier_score_loss(y_train, p_train_shuffled)\n",
    "br_test_shuffled = brier_score_loss(y_test, p_test_shuffled)\n",
    "\n",
    "improve_ll_test_shuffled = (ll_test_base - ll_test_shuffled)/ll_test_base\n",
    "improve_br_test_shuffled = (br_test_base - br_test_shuffled)/br_test_base\n",
    "\n",
    "print(\"\\n=== Model vs Baseline (SHUFFLED labels) ===\")\n",
    "print(f\"log_loss test  model={ll_test_shuffled:.4f}  base={ll_test_base:.4f}\")\n",
    "print(f\"Brier    test  model={br_test_shuffled:.4f}  base={br_test_base:.4f}\")\n",
    "print(f\"Test improvement vs base (log_loss): {improve_ll_test_shuffled*100:6.2f}%\")\n",
    "print(f\"Test improvement vs base (Brier):    {improve_br_test_shuffled*100:6.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8428c1",
   "metadata": {},
   "source": [
    "Given large standard vs shuffled gap 35-45% varying from brier vs log_loss, I determined it is unnecessary to further define a quantifiable threshold, although it's usually best practice to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d06a60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 2025-05-27 00:00:00\n",
      "PASS: True\n",
      "diff:\n",
      " Ticker\n",
      "ASML_vol_adj_mom    0.0\n",
      "SPY_returns         0.0\n",
      "SMH_returns         0.0\n",
      "Name: 2025-05-27 00:00:00, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# As-of-Freeze Test\n",
    "T = df_raw.index[int(len(df_raw)*0.90)]  # pick an interior cutoff\n",
    "\n",
    "def freeze(df):\n",
    "    c = df[[(\"Close\",\"ASML\"),(\"Close\",\"SMH\"),(\"Close\",\"SPY\")]].copy()\n",
    "    c.columns = c.columns.droplevel(0)\n",
    "    c[\"ASML_vol_adj_mom\"] = c[\"ASML\"].pct_change(L) / c[\"ASML\"].rolling(L).std()\n",
    "    c[\"SPY_returns\"] = c[\"SPY\"].pct_change(L)\n",
    "    c[\"SMH_returns\"] = c[\"SMH\"].pct_change(L)\n",
    "    return c[[\"ASML_vol_adj_mom\",\"SPY_returns\",\"SMH_returns\"]].replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "xf, xc = freeze(df_raw), freeze(df_raw.loc[:T])\n",
    "d = (xf.loc[T] - xc.loc[T]).abs()\n",
    "\n",
    "print(\"T:\", T)\n",
    "print(\"PASS:\", (d.max(skipna=True) <= 1e-10) and not (xf.loc[T].isna() ^ xc.loc[T].isna()).any())\n",
    "print(\"diff:\\n\", d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22a2b1",
   "metadata": {},
   "source": [
    "It's just an examination of whether information at t is exposed to additional information at t+1 due to lookback window. We're declare T then model with it to produce segmented data. From there, we compare the segmented data xc to the full history data xf, in the ways we derived the input features. If no future data (t+1) has contaminated data at t, then the gap between a set of randomly selected column from start -> T should be 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a42587c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank check: PASS\n",
      "Mean abs calibration error: 0.0677\n",
      "\n",
      "Bucket stats:\n",
      "   bucket   n   avg_p  hit_rate   error\n",
      "0       1  45  0.2298    0.1333  0.0965\n",
      "1       2  45  0.2588    0.1778  0.0810\n",
      "2       3  45  0.2721    0.1556  0.1165\n",
      "3       4  44  0.2839    0.3182 -0.0342\n",
      "4       5  45  0.2951    0.4000 -0.1049\n",
      "5       6  45  0.3056    0.3111 -0.0055\n",
      "6       7  44  0.3181    0.2273  0.0908\n",
      "7       8  45  0.3356    0.2889  0.0467\n",
      "8       9  45  0.3591    0.3556  0.0035\n",
      "9      10  45  0.4143    0.5111 -0.0968\n"
     ]
    }
   ],
   "source": [
    "# Probability rank/calibration\n",
    "n_buckets = 10\n",
    "\n",
    "calib = pd.DataFrame({\n",
    "    \"p\": p_test.values,\n",
    "    \"y\": y_test.values\n",
    "}).sort_values(\"p\")\n",
    "\n",
    "calib[\"bucket\"] = pd.qcut(calib[\"p\"], q=n_buckets, labels=False, duplicates=\"drop\")\n",
    "\n",
    "stats = calib.groupby(\"bucket\").agg(\n",
    "    n=(\"y\", \"size\"),\n",
    "    avg_p=(\"p\", \"mean\"),\n",
    "    hit_rate=(\"y\", \"mean\"),\n",
    ").reset_index()\n",
    "\n",
    "stats[\"bucket\"] += 1\n",
    "stats[\"error\"] = stats[\"avg_p\"] - stats[\"hit_rate\"]\n",
    "\n",
    "rank_check = stats[\"avg_p\"].is_monotonic_increasing\n",
    "mae = stats[\"error\"].abs().mean()\n",
    "\n",
    "print(\"Rank check:\", \"PASS\" if rank_check else \"FAIL\")\n",
    "print(\"Mean abs calibration error:\", round(mae, 4))\n",
    "print(\"\\nBucket stats:\")\n",
    "print(stats[[\"bucket\", \"n\", \"avg_p\", \"hit_rate\", \"error\"]].round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9539a551",
   "metadata": {},
   "source": [
    "Use graphs to inspect... \n",
    "3D graph: each axis is an input feature. Color data points using y_trade classification. Would make it interesting. \n",
    "Gotta compute the actual outputs and derive an interpretation of them\n",
    "Any important interpretation should be followed by a graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
